---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Kernel center adaptation in the reproducing kernel Hilbert space embedding
  method
subtitle: ''
summary: ''
authors:
- admin
- Jia Guo
- Andrew Kurdila
tags: 
  - data-driven modeling
  - learning
categories: []
date: '2022-01-01'
lastmod: 2022-11-12T05:28:29-05:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-11-12T10:28:29.760682Z'
publication_types:
- '2'
abstract: 'The performance of adaptive estimators that employ embedding in reproducing kernel Hilbert spaces (RKHS) depends on the choice of the location of basis kernel centers. Parameter convergence and error approximation rates depend on where and how the kernel centers are distributed in the state-space. In this article, we develop the theory that relates parameter convergence and approximation rates to the position of kernel centers. We develop criteria for choosing kernel centers in a specific class of systems by exploiting the fact that the state trajectory regularly visits the neighborhood of the positive limit set. Two algorithms, based on centroidal Voronoi tessellations and Kohonen self-organizing maps, are derived to choose kernel centers in the RKHS embedding method. Finally, we implement these methods on two practical examples and test their effectiveness.'
publication: '*International Journal of Adaptive Control and Signal Processing*'
---
